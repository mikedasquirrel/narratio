{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Narrative Optimization Testbed - Quick Start\n",
        "\n",
        "This notebook demonstrates the core concepts and workflow of the narrative optimization research framework.\n",
        "\n",
        "## Overview\n",
        "\n",
        "The framework tests whether **\"better stories win\"** - whether narrative-driven feature engineering outperforms statistical baselines.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Imports successful\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"✓ Imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Toy Data\n",
        "\n",
        "We use the 20newsgroups dataset as a generic testbed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded existing toy dataset\n",
            "Training samples: 400\n",
            "Test samples: 100\n",
            "Categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
            "\n",
            "Example document (first 200 chars):\n",
            "I am working on a project where we are going to be including\n",
            "both still and moving grapics within a database.  Of course\n",
            "JPEG and MPEG come to mind as the formats of choice for the\n",
            "various files.  How...\n"
          ]
        }
      ],
      "source": [
        "from src.utils.toy_data import quick_load_toy_data\n",
        "\n",
        "# Load or generate toy dataset\n",
        "data = quick_load_toy_data(data_dir='../data/toy')\n",
        "\n",
        "X_train = data['X_train']\n",
        "y_train = data['y_train']\n",
        "X_test = data['X_test']\n",
        "y_test = data['y_test']\n",
        "target_names = data['target_names']\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "print(f\"Categories: {target_names}\")\n",
        "print(f\"\\nExample document (first 200 chars):\\n{X_train[0][:200]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build a Narrative Pipeline\n",
        "\n",
        "Let's create a simple narrative pipeline that tests whether semantic understanding helps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Pipeline built successfully!\n",
            "Steps: ['semantic_features', 'scaler', 'classifier']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from src.transformers.semantic import SemanticNarrativeTransformer\n",
        "from src.pipelines.narrative_pipeline import NarrativePipeline\n",
        "\n",
        "# Build pipeline with narrative metadata\n",
        "pipeline = NarrativePipeline(\n",
        "    narrative_name=\"Semantic Understanding Test\",\n",
        "    hypothesis=\"Semantic embeddings capture meaning better than word counts\",\n",
        "    expected_outcome=\"Improved classification by understanding deeper meaning\"\n",
        ")\n",
        "\n",
        "# Add transformation steps\n",
        "pipeline.add_step(\n",
        "    'semantic_features',\n",
        "    SemanticNarrativeTransformer(n_components=30, n_clusters=8),\n",
        "    rationale=\"Extract semantic embeddings and cluster membership\"\n",
        ")\n",
        "\n",
        "pipeline.add_step(\n",
        "    'scaler',\n",
        "    StandardScaler(),\n",
        "    rationale=\"Normalize features for classifier\"\n",
        ")\n",
        "\n",
        "pipeline.add_step(\n",
        "    'classifier',\n",
        "    LogisticRegression(max_iter=1000, random_state=42),\n",
        "    rationale=\"Linear classifier on semantic features\"\n",
        ")\n",
        "\n",
        "# Build the sklearn Pipeline\n",
        "sklearn_pipeline = pipeline.build()\n",
        "\n",
        "print(\"✓ Pipeline built successfully!\")\n",
        "print(f\"Steps: {list(sklearn_pipeline.named_steps.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "This is a quick introduction! For the full workflow, run:\n",
        "\n",
        "```bash\n",
        "python run_experiment.py -e 01_baseline_comparison\n",
        "```\n",
        "\n",
        "See the documentation in `docs/` for more details on creating custom transformers and experiments.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
