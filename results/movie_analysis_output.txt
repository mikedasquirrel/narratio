======================================================================
COMPLETE MOVIE ANALYSIS PIPELINE
======================================================================

STEP 1: Merging movie datasets...
----------------------------------------------------------------------
================================================================================
MOVIE DATASET AMALGAMATION
================================================================================

ðŸ“‚ Loading datasets...
  Loading CMU metadata...
  Loading CMU plot summaries...
  âœ“ CMU: 81,741 movies
  Loading IMDB data...
  âœ“ IMDB: 6,047 movies
  Loading MovieLens data...
  âœ“ MovieLens: 9,742 movies

ðŸ”§ Normalizing data for joins...
  âœ“ Normalized all titles and years

ðŸ”— Joining datasets...
  Join 1: CMU â†” IMDB (wikipedia_id)...
    âœ“ 6,047 direct matches
  Join 2: Result â†” MovieLens (title + year)...
    âœ“ 5,247 MovieLens matches

ðŸ“‹ Creating unified schema...
    Processed 5,000 movies...
    Processed 10,000 movies...
    Processed 15,000 movies...
    Processed 20,000 movies...
    Processed 25,000 movies...
    Processed 30,000 movies...
    Processed 35,000 movies...
    Processed 40,000 movies...
    Processed 45,000 movies...
    Processed 50,000 movies...
    Processed 55,000 movies...
    Processed 60,000 movies...
    Processed 65,000 movies...
    Processed 70,000 movies...
    Processed 75,000 movies...
    Processed 80,000 movies...
  âœ“ Created 81,747 unified movie records

ðŸ“Š Dataset statistics...
  Total movies: 81,747
  With plot summaries: 6,051 (7.4%)
  With cast info: 5,987 (7.3%)
  With box office: 8,406 (10.3%)
  With user ratings: 5,236 (6.4%)
  With genres: 8,266 (10.1%)
  Rich movies (60%+ complete): 6,051
  Average completeness: 8.2%
  Year range: 1010 - 2016

ðŸ’¾ Saving to data/domains/movies_merged_complete.json...
Traceback (most recent call last):
  File "/Users/michaelsmerconish/Desktop/RandomCode/novelization/scripts/merge_movie_datasets.py", line 398, in <module>
    json.dump(output_data, f, indent=2)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/__init__.py", line 179, in dump
    for chunk in iterable:
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/encoder.py", line 431, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/encoder.py", line 405, in _iterencode_dict
    yield from chunks
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/encoder.py", line 405, in _iterencode_dict
    yield from chunks
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/encoder.py", line 405, in _iterencode_dict
    yield from chunks
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/encoder.py", line 438, in _iterencode
    o = _default(o)
  File "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type int64 is not JSON serializable

ERROR: Dataset merge failed. Aborting.
