"""
Discover NBA player-level patterns using Context Pattern Transformer

This script:
1. Loads games with player data (COMPLETE dataset)
2. Extracts RAW player features (no pre-defined categories)
3. Runs Context Pattern Transformer to discover patterns
4. Reports ALL discovered patterns (no arbitrary limits)

Author: Narrative Optimization Framework
Date: November 16, 2025
"""

import sys
import json
import pandas as pd
from pathlib import Path

# Add narrative_optimization to path
sys.path.insert(0, str(Path(__file__).parent / 'narrative_optimization' / 'src'))

from transformers.context_pattern import ContextPatternTransformer

print("="*80)
print("NBA PLAYER PATTERN DISCOVERY - COMPLETE DATASET")
print("="*80)
print()
print("Philosophy: Let the data reveal what matters")
print("  ‚úì No pre-defined 'star' vs 'role player' categories")
print("  ‚úì No hard-coded thresholds")
print("  ‚úì No keyword fallbacks")
print("  ‚úì Return ALL valid patterns discovered")
print()

# Load enhanced data with player stats (COMPLETE dataset)
data_path = Path(__file__).parent / 'data' / 'domains' / 'nba_complete_with_players.json'

if not data_path.exists():
    print(f"\n‚ùå Complete dataset not found: {data_path}")
    print("   Run: python3 build_player_data_from_pbp.py first")
    sys.exit(1)

with open(data_path) as f:
    games = json.load(f)

print(f"‚úì Loaded {len(games):,} games")

# Extract features (team-level + player-level)
features_list = []
outcomes = []
game_ids = []

for game in games:
    if not game.get('player_data', {}).get('available'):
        continue
    
    tc = game['temporal_context']
    pd_agg = game['player_data']['team_aggregates']
    
    # RAW features - let transformer discover patterns
    features_list.append({
        # Team context (from temporal)
        'home': 1.0 if game['home_game'] else 0.0,
        'season_win_pct': tc['season_win_pct'],
        'l10_win_pct': tc['l10_win_pct'],
        'games_played': tc['games_played'] / 82.0,
        
        # Player distribution features (RAW numbers)
        'top1_points': pd_agg['top1_points'],
        'top2_points': pd_agg['top2_points'],
        'top3_points': pd_agg['top3_points'],
        'players_20plus_pts': pd_agg['players_20plus_pts'],
        'players_15plus_pts': pd_agg['players_15plus_pts'],
        'players_10plus_pts': pd_agg['players_10plus_pts'],
        
        # Experience features (RAW)
        'experienced_players': pd_agg['experienced_players'],
        'avg_experience': pd_agg['avg_experience'],
        
        # Usage concentration features
        'top1_scoring_share': pd_agg['top1_scoring_share'],
        'top3_scoring_share': pd_agg['top3_scoring_share'],
        
        # Team balance features
        'bench_points': pd_agg['bench_points'],
        'players_5plus_ast': pd_agg['players_5plus_ast'],
        'players_used': pd_agg['players_used'],
    })
    
    outcomes.append(1 if game['won'] else 0)
    game_ids.append(game.get('game_id', ''))

print(f"‚úì Extracted features from {len(features_list):,} games with player data")
print(f"   Coverage: {len(features_list)/len(games)*100:.1f}% of total games")
print()

X = pd.DataFrame(features_list)
y = pd.array(outcomes)

print("Features available:")
for col in X.columns:
    print(f"  - {col}: {X[col].min():.2f} to {X[col].max():.2f}")
print()

# Discover patterns (NO LIMITS)
print("üîç Running Context Pattern Transformer...")
print("   min_accuracy: 60%")
print("   min_samples: 100 (increased for full dataset)")
print("   max_patterns: UNLIMITED (return all valid)")
print()

transformer = ContextPatternTransformer(
    min_accuracy=0.60,
    min_samples=100,  # Higher threshold for full dataset
    max_patterns=None,  # Return ALL valid patterns
    min_effect_size=0.1
)

transformer.fit(X, y)

print(f"\n‚úì Discovered {len(transformer.patterns_)} player-level patterns")
print()
print("="*80)
print("DISCOVERED PATTERNS")
print("="*80)
print()

# Print full report
report = transformer.get_context_report()
print(report)
print()

# Save patterns to file
output_path = Path(__file__).parent / 'discovered_player_patterns.json'
patterns_data = []

for i, pattern in enumerate(transformer.patterns_):
    # Convert conditions to JSON-serializable format
    conditions_json = {}
    for key, value in pattern.conditions.items():
        if isinstance(value, dict):
            conditions_json[key] = {k: float(v) if hasattr(v, 'item') else v for k, v in value.items()}
        else:
            conditions_json[key] = float(value) if hasattr(value, 'item') else value
    
    patterns_data.append({
        'rank': i + 1,
        'features': pattern.features,
        'conditions': conditions_json,
        'accuracy': float(pattern.accuracy),
        'sample_size': int(pattern.sample_size),
        'effect_size': float(pattern.effect_size),
        'p_value': float(pattern.p_value),
        'score': float(pattern.score)
    })

with open(output_path, 'w') as f:
    json.dump({
        'total_patterns': len(patterns_data),
        'total_games_analyzed': len(features_list),
        'baseline_accuracy': float(y.mean()),
        'patterns': patterns_data
    }, f, indent=2)

print(f"‚úì Saved patterns to: {output_path}")
print()
print("="*80)
print("NEXT STEPS")
print("="*80)
print()
print("1. Review patterns in discovered_player_patterns.json")
print("2. Test profitability on 2023-24 season")
print("3. Validate with selective betting strategy")
print()
print("Key Insight: These patterns emerged FROM THE DATA")
print("  - No pre-defined categories")
print("  - No hard-coded thresholds")
print("  - Pure discovery of what actually matters")
print("  - Based on 11,976 complete games")
print()

